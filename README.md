# CoralCake

CoralCake is a professional platform designed to compare the performance of various Large Language Models (LLMs) in real-time. It empowers developers, researchers, and organizations to run prompts across multiple LLM providers and evaluate their performance, latency, token usage, and associated costs.

## What is CoralCake?

CoralCake enables you to:
- Run the same prompt across leading LLMs (including OpenAI and Mistral models)
- Instantly compare response time, cost, and token consumption for each model
- Gain actionable insights for model selection based on real-world requirements

Whether you are evaluating LLMs for integration, optimizing prompt engineering, or simply exploring new models, CoralCake streamlines benchmarking and decision-making.

## Technologies Used

- **Next.js**: Modern React framework for fast, scalable web applications
- **Supabase**: Backend as a Service for authentication and data storage
- **TypeScript**: Type-safe JavaScript for improved reliability
- **Doppler**: Secret management for environment variables
- **OpenAI & Mistral APIs**: Integration to leading LLM providers
- **Helicone**: API proxy for tracking usage and latency

## Use Cases

- **Prompt Benchmarking**: Compare LLMs side-by-side to identify the most cost-effective and performant model for your application.
- **Model Evaluation**: Test new LLMs as they are released and monitor their capabilities.
- **Cost Analysis**: Estimate and control token and monetary costs associated with different models.
- **Latency Testing**: Measure response times under real-world conditions.
- **AI Product Development**: Integrate LLM performance insights into your product workflow.

---

Visit the live app at: [https://coralcake.vercel.app](https://coralcake.vercel.app)
